# Проверщик ДЗ (ДЗ-чекер)

Система автоматической проверки домашних заданий стажёров с использованием LLM.

## Назначение

ДЗ-чекер — это агент, который:
- Принимает ответы стажёров из LMS
- Сопоставляет их с нормативными материалами из репозитория
- Оценивает по заданным критериям (рубрикам) с помощью LLM
- Возвращает структурированную обратную связь в LMS

---

## Системы и их взаимодействие

```
                                    ┌───────────────┐
                                    │  Репозиторий  │
                                    │  (норматив,   │
                                    │   рубрики)    │
                                    └───────┬───────┘
                                            │
                                            │ [A3] Контекст
                                            ▼
┌──────────┐   [A1]    ┌─────────┐   [A2]   ┌───────────┐   [A4]   ┌─────────┐
│          │  Ответ   │         │  Пакет  │           │  Запрос │         │
│  Стажёр  │─────────▶│   LMS   │────────▶│ ДЗ-чекер  │────────▶│   LLM   │
│          │          │         │         │           │         │         │
│          │◀─────────│         │◀────────│           │◀────────│         │
└──────────┘   [A7]   └─────────┘   [A6]  └───────────┘   [A5]   └─────────┘
              Показ              Результат           Оценка
```

**Обозначения артефактов:** [A1]–[A7] — см. раздел «Артефакты».

### Роли систем

| Система | Роль | Данные |
|---------|------|--------|
| **Стажёр** | Источник ответа | Текст ответа на вопрос ДЗ |
| **LMS (Aisystant)** | Оркестратор процесса | Вопросы, ответы, метаданные, результаты |
| **ДЗ-чекер** | Движок проверки | Логика сборки контекста и запросов |
| **Репозиторий** | Источник норматива | Тексты руководств, рубрики, карта вопросов |
| **LLM** | Исполнитель проверки | Сопоставление ответа с критериями |

---

## Артефакты (пакеты), которые "текут" по процессу

| № | Артефакт | Откуда → Куда | Описание |
|---|----------|---------------|----------|
| A1 | Запись ответа | Стажёр → LMS | Исходный ответ стажёра со статусом «ожидает проверки» |
| A2 | Пакет на проверку | LMS → ДЗ-чекер | Ответ + вопрос + метаданные в формате JSON |
| A3 | Контекст проверки | Репозиторий → ДЗ-чекер | Норматив (фрагмент руководства) + рубрика |
| A4 | Запрос к LLM | ДЗ-чекер → LLM | Промпт с ответом, нормативом и критериями |
| A5 | Результат проверки | LLM → ДЗ-чекер | Вердикт, баллы, замечания, рекомендации |
| A6 | Пакет результата | ДЗ-чекер → LMS | Форматированный комментарий для записи |
| A7 | Обновлённая запись | LMS → Стажёр | Ответ с комментарием ИИ-наставника |

---

## Процесс проверки по шагам

### Шаг 1. Стажёр отправляет ответ

**Вход:**
- Текст ответа от стажёра
- Действие «Отправить»

**Действие (в интерфейсе LMS):**
- Стажёр вводит текст ответа в поле
- Нажимает кнопку «Отправить»

**Выход → LMS (артефакт A1: Запись ответа):**
- идентификатор попытки (`attempt_id`)
- идентификатор стажёра (`student_id`)
- идентификатор вопроса (`question_id`)
- текст ответа
- время отправки
- статус: `pending_review`

---

### Шаг 2. LMS формирует пакет на проверку

**Вход:**
- Артефакт A1 (запись ответа)
- Данные вопроса из банка заданий LMS

**Действие (внутри LMS):**
- Извлечение текста вопроса по `question_id`
- Добавление метаданных (курс, урок, раздел)
- Формирование JSON-пакета
- Отправка в ДЗ-чекер (webhook / API / файл)

**Выход → ДЗ-чекер (артефакт A2: Пакет на проверку):**
```json
{
  "packet_type": "check_request",
  "version": "1.0",
  "attempt_id": "att_12345",
  "student_id": "student_001",
  "question": {
    "id": "q_phys_world_01",
    "text": "Почему физический мир может иметь множество описаний?",
    "course_id": "systems-thinking-101",
    "lesson_id": "lesson_01"
  },
  "answer": {
    "text": "Любая модель части физического мира...",
    "submitted_at": "2025-09-08T20:28:00Z"
  }
}
```

---

### Шаг 3. ДЗ-чекер принимает и валидирует пакет

**Вход:**
- Артефакт A2 (пакет на проверку)

**Действие (внутри ДЗ-чекера):**
- Валидация JSON по схеме `check_request.json`
- Проверка обязательных полей
- Создание записи в журнале проверок
- Присвоение `check_id` для трассировки

**Выход → внутренний (запись в журнале):**
- `check_id`: уникальный идентификатор проверки
- `status`: `in_progress`
- `received_at`: время получения

---

### Шаг 4. ДЗ-чекер получает контекст из репозитория

**Вход:**
- Артефакт A2 (пакет на проверку) — `question.id`

**Действие (запрос к репозиторию):**
- Поиск в карте вопросов (`questions_map.yaml`) по `question_id`
- Извлечение пути к разделу руководства
- Загрузка фрагмента текста руководства
- Загрузка рубрики проверки (`rubrics.yaml`)

**Выход → внутренний (артефакт A3: Контекст проверки):**
```json
{
  "question_id": "q_phys_world_01",
  "guide_reference": {
    "path": "content/guides/systems-thinking/chapter-01.md",
    "section": "1.1. Физический мир и ментальное пространство",
    "version": "v2.3.1"
  },
  "normative_content": "Физический мир существует объективно...",
  "rubric": {
    "id": "rubric_conceptual_understanding",
    "name": "Понимание концепции",
    "criteria": [
      {"id": "main_idea", "weight": 40, "description": "..."},
      {"id": "own_example", "weight": 30, "description": "..."}
    ]
  }
}
```

---

### Шаг 5. ДЗ-чекер собирает запрос к LLM

**Вход:**
- Артефакт A2 (пакет на проверку) — вопрос и ответ
- Артефакт A3 (контекст проверки) — норматив и рубрика

**Действие (внутри ДЗ-чекера):**
- Загрузка системного промпта (`system.txt`)
- Загрузка шаблона проверки (`check_template.txt`)
- Подстановка переменных: вопрос, ответ, норматив, критерии
- Формирование API-запроса к LLM

**Выход → LLM (артефакт A4: Запрос к LLM):**
```json
{
  "model": "claude-3-5-sonnet-20241022",
  "max_tokens": 2000,
  "temperature": 0.3,
  "messages": [
    {
      "role": "system",
      "content": "Ты — опытный наставник курса системного мышления..."
    },
    {
      "role": "user",
      "content": "## Вопрос\n{question}\n\n## Ответ студента\n{answer}\n\n## Норматив\n{normative}\n\n## Критерии\n{rubric}\n\n## Формат ответа\nВерни JSON..."
    }
  ]
}
```

---

### Шаг 6. LLM выполняет проверку

**Вход:**
- Артефакт A4 (запрос к LLM)

**Действие (внутри LLM):**
- Анализ ответа студента
- Сопоставление с нормативом
- Оценка по каждому критерию рубрики
- Формирование структурированного ответа

**Выход → ДЗ-чекер (артефакт A5: Результат проверки):**
```json
{
  "verdict": "accepted",
  "score": 85,
  "strengths": [
    "Верно указано, что любая модель фокусируется на определённых свойствах",
    "Хороший пример с программным продуктом"
  ],
  "issues": [
    {
      "criterion": "terminology",
      "issue": "Не использован термин 'описание системы'",
      "suggestion": "Рекомендую использовать точную терминологию"
    }
  ],
  "next_step": "Попробуйте привести ещё один пример из вашей практики",
  "criterion_scores": {
    "main_idea": 40,
    "own_example": 25,
    "terminology": 10,
    "completeness": 10
  }
}
```

---

### Шаг 7. ДЗ-чекер форматирует результат для LMS

**Вход:**
- Артефакт A2 (пакет на проверку) — `attempt_id`
- Артефакт A5 (результат проверки)

**Действие (внутри ДЗ-чекера):**
- Валидация полноты результата
- Форматирование в Markdown для отображения
- Добавление метаданных (модель, время, ссылка на источник)
- Приведение к формату LMS

**Выход → LMS (артефакт A6: Пакет результата):**
```json
{
  "packet_type": "check_result",
  "attempt_id": "att_12345",
  "status": "accepted",
  "score": 85,
  "comment": "**Принято** (85/100)\n\n**Сильные стороны:**\n- Верно указано...\n\n**Замечания:**\n- Не использован термин...\n\n**Следующий шаг:**\nПопробуйте привести ещё один пример...\n\n---\n_Проверено: Claude 3.5 Sonnet | По материалам: Глава 1, раздел 1.1_",
  "checked_at": "2025-09-08T20:35:00Z",
  "model_used": "claude-3-5-sonnet-20241022"
}
```

---

### Шаг 8. LMS записывает результат и показывает стажёру

**Вход:**
- Артефакт A6 (пакет результата)

**Действие (внутри LMS):**
- Поиск попытки по `attempt_id`
- Запись комментария в поле «Комментарий проверяющего»
- Обновление статуса попытки
- Обновление отображения в интерфейсе

**Выход → Стажёр (артефакт A7: Обновлённая запись):**
- Стажёр видит комментарий ИИ-наставника в интерфейсе LMS

---

## Что нужно сделать по каждой системе

### LMS (Aisystant)

| Задача | Приоритет | Описание |
|--------|-----------|----------|
| **API отправки на проверку** | MVP | Эндпоинт или webhook для отправки артефакта A2 в ДЗ-чекер |
| **API приёма результата** | MVP | Эндпоинт для записи артефакта A6 в попытку |
| **Поле «Комментарий ИИ»** | MVP | Новое поле в интерфейсе стажёра для отображения A7 |
| **Маппинг question_id** | MVP | Стабильные идентификаторы вопросов для карты вопросов |
| **Триггер автопроверки** | v0.2 | Автоматический вызов ДЗ-чекера при отправке ответа |
| **Статусы проверки** | v0.2 | Отображение: «На проверке ИИ», «Проверено ИИ», «На проверке наставника» |

### ДЗ-чекер (Репозиторий)

| Задача | Приоритет | Описание |
|--------|-----------|----------|
| **CLI-скрипт проверки** | MVP | `check.py` — приём JSON, возврат результата |
| **Карта вопросов** | MVP | `questions_map.yaml` — связь question_id с руководствами |
| **Рубрики проверки** | MVP | `rubrics.yaml` — критерии с весами для разных типов вопросов |
| **Промпты** | MVP | Системный промпт и шаблон проверки |
| **Интеграция с Claude API** | MVP | Вызов API и парсинг JSON-ответа |
| **JSON Schema** | MVP | Валидация входящих и исходящих пакетов |
| **Webhook-сервер** | v0.2 | HTTP-эндпоинт для приёма запросов от LMS |
| **Очередь задач** | v0.2 | Async-обработка для batch-проверок |
| **Логирование** | v0.2 | Журнал проверок для аудита и отладки |

### Репозиторий (Контент)

| Задача | Приоритет | Описание |
|--------|-----------|----------|
| **Структура руководств** | MVP | Организация `content/guides/` с чёткими разделами |
| **Якоря разделов** | MVP | Заголовки с идентификаторами для точной навигации |
| **Наполнение карты вопросов** | MVP | Связать все вопросы ДЗ с разделами руководств |
| **Версионирование** | v0.2 | Git tags для отслеживания версий материалов |

### LLM (Внешний сервис)

| Задача | Приоритет | Описание |
|--------|-----------|----------|
| **API-ключ** | MVP | Настройка доступа к Claude API |
| **Fallback-модели** | v0.3 | Резервные модели (GPT-4, Gemini) при недоступности |
| **Rate limiting** | v0.2 | Контроль частоты запросов |

---

## Интерфейс для стажёра (третий экран)

```
┌────────────────────────────────────────────────────────────┐
│  Комментарий ИИ-наставника                                │
├────────────────────────────────────────────────────────────┤
│                                                            │
│  ✓ Принято (85/100)                    08.09.2025 в 20:35 │
│                                                            │
│  Сильные стороны:                                          │
│  • Верно указано, что любая модель фокусируется на        │
│    определённых свойствах                                  │
│  • Хороший пример с программным продуктом                  │
│                                                            │
│  Замечания:                                                │
│  • Не использован термин «описание системы» —              │
│    рекомендую использовать точную терминологию             │
│                                                            │
│  Следующий шаг:                                            │
│  Попробуйте привести ещё один пример из вашей практики    │
│                                                            │
│  ─────────────────────────────────────────────────────     │
│  Проверено: Claude 3.5 Sonnet                             │
│  По материалам: Глава 1, раздел 1.1                        │
│                                                            │
└────────────────────────────────────────────────────────────┘
```

---

## Ключевые компоненты в репозитории

### Карта вопросов (questions_map.yaml)

Связывает идентификаторы вопросов LMS с материалами:

```yaml
questions:
  q_phys_world_01:
    title: "Множество описаний физического мира"
    guide_path: "content/guides/systems-thinking/chapter-01.md"
    guide_section: "1.1. Физический мир и ментальное пространство"
    rubric_id: "rubric_conceptual_understanding"
    keywords:
      - модель
      - описание
      - физический мир
```

### Рубрики проверки (rubrics.yaml)

Критерии с весами для оценки:

```yaml
rubrics:
  rubric_conceptual_understanding:
    name: "Понимание концепции"
    criteria:
      - id: main_idea
        weight: 40
        description: "Студент передал ключевую идею из материала"
      - id: own_example
        weight: 30
        description: "Приведён собственный пример"
      - id: terminology
        weight: 20
        description: "Корректно использована терминология"
      - id: completeness
        weight: 10
        description: "Ответ полный"
```

---

## Пороги автоматических решений

| Диапазон баллов | Действие |
|-----------------|----------|
| 80-100 | Автоматически принять |
| 60-79 | Отправить наставнику на review |
| 0-59 | Автоматически вернуть на доработку |

---

## Реализация

Код агента: `agents-core/homework-checker/`

```
agents-core/homework-checker/
├── README.md                 # Техническая документация
├── manifest.json             # Манифест агента
├── check.py                  # CLI-скрипт проверки
├── config.yaml               # Конфигурация
├── data/
│   ├── questions_map.yaml    # Карта вопросов
│   ├── rubrics.yaml          # Рубрики
│   └── prompts/              # Промпты для LLM
├── schemas/                  # JSON Schema
└── examples/                 # Примеры данных
```

### Использование (MVP)

```bash
# Проверка одного ответа
python3 agents-core/homework-checker/check.py \
  --input answer.json \
  --output result.json
```

---

## Roadmap

### v0.1 — MVP
- CLI-интерфейс
- Загрузка карты вопросов и рубрик
- Интеграция с Claude API

### v0.2 — Интеграция
- Webhook для LMS
- Batch-обработка
- Логирование

### v0.3 — Улучшения
- Fallback на другие LLM
- Кэширование
- Обратная связь от наставников

### v1.0 — Production
- API для LMS
- Dashboard мониторинга
- Поддержка нескольких курсов

---

## Открытые вопросы

1. **Формат обмена с LMS** — webhook, REST API, или файловый обмен?
2. **Хранение результатов** — в LMS, в репозитории, или в отдельной БД?
3. **Роль наставника** — всегда проверяет после ИИ или только спорные случаи?
4. **Версионирование материалов** — как отслеживать, по какой версии руководства проверяли?

---

**Статус:** Концепция
**Дата:** 2025-12-22
