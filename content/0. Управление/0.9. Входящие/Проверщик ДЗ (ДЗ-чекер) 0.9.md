# Проверщик ДЗ (ДЗ-чекер)

Система автоматической проверки домашних заданий стажёров с использованием LLM.

## Назначение

ДЗ-чекер — это агент, который:
- Принимает ответы стажёров из LMS
- Сопоставляет их с нормативными материалами из репозитория
- Оценивает по заданным критериям (рубрикам) с помощью LLM
- Возвращает структурированную обратную связь в LMS

## Системы и их взаимодействие

```
┌─────────────┐     ┌─────────┐     ┌────────────────┐     ┌─────────────┐     ┌─────┐
│   Стажёр    │────▶│   LMS   │────▶│  ДЗ-чекер      │────▶│ Репозиторий │     │ LLM │
│             │     │         │◀────│                │◀────│             │     │     │
└─────────────┘     └─────────┘     │                │────▶│             │     │     │
                         │         │                │◀────└─────────────┘     │     │
                         │         │                │                         │     │
                         │         │                │────────────────────────▶│     │
                         │         │                │◀────────────────────────│     │
                         │         └────────────────┘                         └─────┘
                         │                │
                         │◀───────────────┘
                         ▼
                   ┌─────────────┐
                   │  Стажёр    │
                   │  (видит    │
                   │  результат)│
                   └─────────────┘
```

### Роли систем

| Система | Роль | Данные |
|---------|------|--------|
| **Стажёр** | Источник ответа | Текст ответа на вопрос ДЗ |
| **LMS (Aisystant)** | Оркестратор процесса | Вопросы, ответы, метаданные, результаты |
| **ДЗ-чекер** | Движок проверки | Логика сборки контекста и запросов |
| **Репозиторий** | Источник норматива | Тексты руководств, рубрики, карта вопросов |
| **LLM** | Исполнитель проверки | Сопоставление ответа с критериями |

---

## Артефакты (пакеты), которые "текут" по процессу

1. **Запись ответа в ЛМС** — исходный ответ стажёра
2. **Пакет на проверку** — данные из LMS для ДЗ-чекера
3. **Контекст проверки** — норматив + рубрика из репозитория
4. **Пакет запроса к LLM** — промпт с контекстом
5. **Результат проверки** — ответ LLM
6. **Пакет записи результата** — форматированный результат для LMS
7. **Обновлённая запись** — ответ с комментарием ИИ

---

## Процесс проверки по шагам

### Шаг 1. Стажёр отправляет ответ в ЛМС

**Вход:** текст ответа + действие «Отправить»

**Выход (артефакт #1):**
- идентификатор попытки
- идентификатор стажёра
- идентификатор вопроса
- текст ответа
- время отправки
- статус «ожидает проверки»

### Шаг 2. ЛМС формирует пакет на проверку

**Вход:** запись ответа + данные вопроса из банка заданий

**Выход (артефакт #2 → в ДЗ-чекер):**
```json
{
  "packet_type": "check_request",
  "version": "1.0",
  "attempt_id": "att_12345",
  "student_id": "student_001",
  "question": {
    "id": "q_phys_world_01",
    "text": "Почему физический мир может иметь множество описаний?",
    "course_id": "systems-thinking-101",
    "lesson_id": "lesson_01"
  },
  "answer": {
    "text": "Любая модель части физического мира...",
    "submitted_at": "2025-09-08T20:28:00Z"
  }
}
```

### Шаг 3. ДЗ-чекер принимает пакет

**Действия:**
- Проверка корректности данных
- Создание записи проверки (журналирование)
- Определение, что именно проверять

### Шаг 4. ДЗ-чекер получает норматив из репозитория

**Вход:** пакет на проверку + запрос к репозиторию

**Действия:**
- Поиск в «карте вопросов» по question_id
- Извлечение фрагментов руководства
- Загрузка рубрики проверки

**Выход (артефакт #3: Контекст проверки):**
```json
{
  "question_id": "q_phys_world_01",
  "guide_reference": {
    "path": "content/guides/systems-thinking/chapter-01.md",
    "section": "1.1. Физический мир и ментальное пространство",
    "version": "v2.3.1"
  },
  "normative_content": "Физический мир существует объективно...",
  "rubric": {
    "id": "rubric_conceptual_understanding",
    "name": "Понимание концепции",
    "criteria": [...]
  }
}
```

### Шаг 5. ДЗ-чекер собирает запрос к LLM

**Вход:** пакет на проверку + контекст проверки

**Выход (артефакт #4 → в LLM):**
- Системный промпт (роль наставника)
- Текст вопроса
- Текст ответа студента
- Нормативные фрагменты
- Критерии оценки
- Требования к формату результата

### Шаг 6. LLM возвращает результат

**Выход (артефакт #5 → в ДЗ-чекер):**
```json
{
  "verdict": "accepted",
  "score": 85,
  "strengths": [
    "Верно указано, что любая модель фокусируется на определённых свойствах",
    "Хороший пример с программным продуктом"
  ],
  "issues": [
    {
      "criterion": "terminology",
      "issue": "Не использован термин 'описание системы'",
      "suggestion": "Рекомендую использовать точную терминологию"
    }
  ],
  "next_step": "Попробуйте привести ещё один пример из вашей практики"
}
```

### Шаг 7. ДЗ-чекер готовит запись для ЛМС

**Действия:**
- Проверка полноты результата
- Форматирование под требования LMS

**Выход (артефакт #6 → в ЛМС):**
```json
{
  "packet_type": "check_result",
  "attempt_id": "att_12345",
  "comment": "**Принято** (85/100)\n\n**Сильные стороны:**\n- ...",
  "status": "accepted",
  "score": 85
}
```

### Шаг 8. ЛМС записывает результат

Стажёр видит комментарий ИИ-наставника в интерфейсе.

---

## Интерфейс для стажёра (третий экран)

```
┌────────────────────────────────────────────────────────────┐
│  Комментарий ИИ-наставника                                │
├────────────────────────────────────────────────────────────┤
│                                                            │
│  ✓ Принято (85/100)                    08.09.2025 в 20:35 │
│                                                            │
│  Сильные стороны:                                          │
│  • Верно указано, что любая модель фокусируется на        │
│    определённых свойствах                                  │
│  • Хороший пример с программным продуктом                  │
│                                                            │
│  Замечания:                                                │
│  • Не использован термин «описание системы» —              │
│    рекомендую использовать точную терминологию             │
│                                                            │
│  Следующий шаг:                                            │
│  Попробуйте привести ещё один пример из вашей практики    │
│                                                            │
│  ─────────────────────────────────────────────────────     │
│  Проверено: Claude 3.5 Sonnet                             │
│  По материалам: Глава 1, раздел 1.1                        │
│                                                            │
└────────────────────────────────────────────────────────────┘
```

---

## Ключевые компоненты в репозитории

### Карта вопросов (questions_map.yaml)

Связывает идентификаторы вопросов LMS с материалами:

```yaml
questions:
  q_phys_world_01:
    title: "Множество описаний физического мира"
    guide_path: "content/guides/systems-thinking/chapter-01.md"
    guide_section: "1.1. Физический мир и ментальное пространство"
    rubric_id: "rubric_conceptual_understanding"
    keywords:
      - модель
      - описание
      - физический мир
```

### Рубрики проверки (rubrics.yaml)

Критерии с весами для оценки:

```yaml
rubrics:
  rubric_conceptual_understanding:
    name: "Понимание концепции"
    criteria:
      - id: main_idea
        weight: 40
        description: "Студент передал ключевую идею из материала"
      - id: own_example
        weight: 30
        description: "Приведён собственный пример"
      - id: terminology
        weight: 20
        description: "Корректно использована терминология"
      - id: completeness
        weight: 10
        description: "Ответ полный"
```

---

## Пороги автоматических решений

| Диапазон баллов | Действие |
|-----------------|----------|
| 80-100 | Автоматически принять |
| 60-79 | Отправить наставнику на review |
| 0-59 | Автоматически вернуть на доработку |

---

## Реализация

Код агента: `agents-core/homework-checker/`

```
agents-core/homework-checker/
├── README.md                 # Техническая документация
├── manifest.json             # Манифест агента
├── check.py                  # CLI-скрипт проверки
├── config.yaml               # Конфигурация
├── data/
│   ├── questions_map.yaml    # Карта вопросов
│   ├── rubrics.yaml          # Рубрики
│   └── prompts/              # Промпты для LLM
├── schemas/                  # JSON Schema
└── examples/                 # Примеры данных
```

### Использование (MVP)

```bash
# Проверка одного ответа
python3 agents-core/homework-checker/check.py \
  --input answer.json \
  --output result.json
```

---

## Roadmap

### v0.1 — MVP
- CLI-интерфейс
- Загрузка карты вопросов и рубрик
- Интеграция с Claude API

### v0.2 — Интеграция
- Webhook для LMS
- Batch-обработка
- Логирование

### v0.3 — Улучшения
- Fallback на другие LLM
- Кэширование
- Обратная связь от наставников

### v1.0 — Production
- API для LMS
- Dashboard мониторинга
- Поддержка нескольких курсов

---

## Открытые вопросы

1. **Формат обмена с LMS** — webhook, REST API, или файловый обмен?
2. **Хранение результатов** — в LMS, в репозитории, или в отдельной БД?
3. **Роль наставника** — всегда проверяет после ИИ или только спорные случаи?
4. **Версионирование материалов** — как отслеживать, по какой версии руководства проверяли?

---

**Статус:** Концепция
**Дата:** 2025-12-22
